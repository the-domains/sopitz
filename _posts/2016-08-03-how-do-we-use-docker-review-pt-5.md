---
datePublished: '2016-08-03T15:15:57.943Z'
hasPage: true
author: []
via: {}
dateModified: '2016-08-03T15:15:48.822Z'
title: How do we use Docker? (Review Pt. 5)
publisher: {}
description: >-
  We at [eForce21](http://www.eforce21.com) use Docker in various customer
  projects as well as for our own infrastructure. I want to give you some real
  life `Dockerfile`s and `docker-compose.yml`s that give you an idea of what you
  can do with docker. Hint: not all of those examples will automatically work
  out of the box for you guys because some of the `Dockerfiles` cannot be
  published due to NDAs and confidentiality concerns. But please just leave me a
  comment or a tweet at [@_sopitz](https://twitter.com/_sopitz). I'm happy to
  help.
starred: false
sourcePath: _posts/2016-08-03-how-do-we-use-docker-review-pt-5.md
url: how-do-we-use-docker-review-pt-5/index.html
_type: MediaObject

---
![](https://the-grid-user-content.s3-us-west-2.amazonaws.com/2a24c345-a51e-4cd8-b985-11f31d1b2e3c.png)

## How do we use Docker? (Review Pt. 5)

We at \[eForce21\](http://www.eforce21.com) use Docker in various customer projects as well as for our own infrastructure. I want to give you some real life \`Dockerfile\`s and \`docker-compose.yml\`s that give you an idea of what you can do with docker. Hint: not all of those examples will automatically work out of the box for you guys because some of the \`Dockerfiles\` cannot be published due to NDAs and confidentiality concerns. But please just leave me a comment or a tweet at \[@\_sopitz\](https://twitter.com/\_sopitz). I'm happy to help.

\# jwilder/nginx-proxy  
\[That's\](https://github.com/jwilder/nginx-proxy) our magical tool. We reverse proxy all our applications on our servers for domain-name, ssl and access management. It will basically do everything for you. You will map the docker socket into the container and it listens for new containers, stopped containers and will perform all the actions necessary to make you happy. Our \`Dockerfile\` looks like this:

<pre\>  
FROM jwilder/nginx-proxy

COPY config/vhosts/\* /etc/nginx/vhost.d/  
COPY config/global/\* /etc/nginx/conf.d/  
</pre\>

There is a file in \`config/global/\` called \`proxy.conf\` where we've defined a couple of settings that should be applied for all vhosts. E. g. \`client\_max\_body\_size 0;\` to make sure we can pull and push bigger files to our GitLab or docker-registry.  
\`config/vhosts/\` contains files that resemble the name of your vhost (e. g. simonopitz.me for this domain). You can specify settings for a single vhost with these files. When you build the \`Dockerfile\` all your vhosts will be configured accordingly during the container build. Once the containers are started you will automatically get your vhost-configs generated by jwilders nginx-proxy.

\# Build-Server  
We have completely automated the setup of our build server. As we keep all our configurations in a git repository all we have to do is a check out on a machine, run a shell script and the whole server is configured. Even the Jenkins Jobs are put in place correctly and work out of the box. Here is what the structure looks like:  
!\[\](/content/images/2015/12/docker-usage-eforce-structure3.png)

The setup.sh basically does all we need. It collects paths for volumes and all settings, builds images, runs all containers and pushes everything to our registry. But have a look yourself:  
<pre\>  
\#/bin/bash -e  
. settings/containers.rc  
. settings/images.rc  
. settings/volumes.rc

OPTIND=1  
default="false"  
while getopts "d?" opt; do  
case "$opt" in  
d ) default="true"  
;;  
esac  
done

shift $((OPTIND-1))

\[ "$1" = "--" \] && shift

\# ask for setting input if not started with -d  
if \[ "$default" != "true" \]; then  
lines=$(cat settings/volumes.rc)  
  
for line in $lines  
do  
value=${line\#\*=}  
variable=${line%%=\*}  
printf "$variable \[$value\] "  
read answer  
if \[ "$answer" == "" \]; then  
echo "$variable=$value" \>\> settings/volumes.rc.tmp  
else  
echo "$variable=$answer" \>\> settings/volumes.rc.tmp  
fi  
done  
cp settings/volumes.rc settings/volumes.rc.previous  
mv settings/volumes.rc.tmp settings/volumes.rc  
fi

\# export settings for envsusbt  
lines=$(cat settings/volumes.rc)  
for line in $lines  
do  
export $line  
done

\# build images  
echo "\[info\] Building Image: ${IMAGE\_NGINX\_PROXY}"  
docker build -t ${IMAGE\_NGINX\_PROXY} nginx-proxy

echo "\[info\] Building Image: ${IMAGE\_SONAR\_POSTGRES}"  
docker build -t ${IMAGE\_SONAR\_POSTGRES} sonarqube/postgres

echo "\[info\] Building Image: ${IMAGE\_SONARQUBE}"  
docker build -t ${IMAGE\_SONARQUBE} sonarqube/sonarqube

echo "\[info\] Building Image: ${IMAGE\_ARTIFACTORY}"  
docker build -t ${IMAGE\_ARTIFACTORY} artifactory

echo "\[info\] Building Image: ${IMAGE\_JENKINS}"  
docker build -t ${IMAGE\_JENKINS} jenkins

\# replace variables in docker-compose file  
cp docker-compose.yml docker-compose.yml.template  
envsubst < docker-compose.yml \> docker-compose.yml.tmp  
mv docker-compose.yml.tmp docker-compose.yml  
\# start infrastructure  
docker-compose up -d  
\# move defaults and backups into place  
echo "\[info\] backing up docker-compose.yml of this run to docker-compose.yml.previous"  
cp docker-compose.yml docker-compose.yml.previous  
mv docker-compose.yml.template docker-compose.yml

\# push images to registry  
echo "\[info\] Pushing Image: ${IMAGE\_NGINX\_PROXY}"  
docker push ${IMAGE\_NGINX\_PROXY}

echo "\[info\] Pushing Image: ${IMAGE\_SONAR\_POSTGRES}"  
docker push ${IMAGE\_SONAR\_POSTGRES}

echo "\[info\] Pushing Image: ${IMAGE\_SONARCUBE}"  
docker push ${IMAGE\_SONARCUBE}

echo "\[info\] Pushing Image: ${IMAGE\_JENKINS}"  
docker push ${IMAGE\_JENKINS}

echo "\[info\] Pushing Image: ${IMAGE\_ARTIFACTORY}"  
docker push ${IMAGE\_ARTIFACTORY}  
</pre\>

You can look into the rest \[here\](https://simonopitz.me/content/images/2015/infrastructure.zip). I've packaged up all the whole scripts and stuff to get your build server up and running with just a few tweaks. Need help? Just tweet me at \[@\_sopitz\](https://twitter.com/\_sopitz). We at \[eForce21\](http://www.eforce21.com) love to help you.

\# Gitlab with Google OAuth  
That's what you need to do to get a Gitlab running with OAuth from Google.

\* Login to your \[Google Developer Console\](https://console.developers.google.com/)   
\* create a new project, e. g. gitlab  
\* configure the OAuth screen (APIs and authentication)  
\* generate login data  
\* configure Google-API

I guess you want to secure the traffic to your Gitlab via SSL. 

<pre\>  
mkdir -p /etc/nginx/ssl  
cd /etc/nginx/ssl  
openssl genrsa -out your\_domain.key 2048  
openssl req -new -x509 -key your\_domain.key -out your\_domain.crt -days 1095  
</pre\>

You can also get a certificate from \[Let's encrypt\](http://letsencrypt.org). Let's Encrypt certificate handling will be covered by a blog post over at the \[eForce21 Blog\](http://www.eforce21.com/blog/).

If you haven't started your nginx-proxy already with the setup I posted earlier, you should do that now.

<pre\>  
docker run -d -v /etc/nginx/certs:/etc/nginx/certs -v /var/run/docker.sock:/tmp/docker.sock --security-opt=label:type:docker\_t -p 80:80 -p 443:443 --name nginx-proxy jwilder/nginx-proxy  
</pre\>

You only need one reverse proxy per IP. It will create name based virtual hosts for you and distribute the traffic to the appropriate applications.

Now we need to start Gitlab itself. We use \`docker-compose\`for this:  
<pre\>  
postgresql:  
image: sameersbn/postgresql:9.4-3  
environment:  
- DB\_USER=gitlab\_user  
- DB\_PASS=gitlab\_password  
- DB\_NAME=gitlabdb  
volumes:  
- /var/lib/docker-data/gitlab/postgresql:/var/lib/postgresql  
gitlab:  
image: sameersbn/gitlab:7.14.1  
links:  
- redis:redisio  
- postgresql:postgresql  
ports:  
- "2222:22"  
environment:  
- TZ=Europe/Berlin  
- GITLAB\_TIMEZONE=Berlin  
- GITLAB\_HTTPS=true  
- GITLAB\_HOST=your\_host  
- GITLAB\_PORT=443  
- GITLAB\_SSH\_PORT=2222  
- GITLAB\_EMAIL=your\_email  
- GITLAB\_EMAIL\_REPLY\_TO=your\_email  
- VIRTUAL\_HOST=git.dev.eforce21.com  
- OAUTH\_GOOGLE\_API\_KEY=client\_id  
- OAUTH\_GOOGLE\_APP\_SECRET=client\_key  
- OAUTH\_GOOGLE\_RESTRICT\_DOMAIN=restrict\_domain  
- OAUTH\_ALLOW\_SSO=true  
- OAUTH\_BLOCK\_AUTO\_CREATED\_USERS=false  
volumes:  
- /var/lib/docker-data/gitlab/gitlab:/home/git/data  
redis:  
image: sameersbn/redis:latest  
volumes:  
- /var/lib/docker-data/gitlab/redis:/var/lib/redis  
</pre\>

And then start it with \`docker-compose up -d\`. Once it's started you can log in with the admin: root:5iveL!fe  
You will have to change that password after login.

\# phensley/docker-dns  
That's what we sometimes use when we cannot use \`docker-compose\`. It will help you to achieve a name based linking system via DNS. Docker will only allow an IP based linking and that has proven to be not flexible enough at times. You will always have to restart more containers than necessary for your update and get that running with phensleys docker-dns container will make more complex setups without \`docker-compose\` very flexible.

Any comments or need help? Just tweet me at \[@\_sopitz\](https://twitter.com/\_sopitz). We at \[eForce21\](http://www.eforce21.com) love to help you.